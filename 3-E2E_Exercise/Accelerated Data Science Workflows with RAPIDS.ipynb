{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>Accelerated Data Science Workflows with RAPIDS</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RAPIDS logo](images/rapids-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [RAPIDS](https://rapids.ai/) suite of software libraries gives data scientists the freedom to execute end-to-end data science and analytics pipelines entirely on GPU accelerators. The software suite relies on NVIDIA CUDA primitives for low-level compute optimization, but exposes that GPU parallelism and high-bandwidth memory speed through user-friendly Python interfaces. RAPIDS enables faster and more iterative development for end to end data science workflows. How to use RAPIDS for these benefits is the focus of this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we will be using a synthetic data set of healthcare patients, and will be attempting to predict whether or not a given patient is likely to be a no-show, or, significantly late, to a scheduled appointment. We will begin with an overview of the data before proceeding into a typical workflow of ingesting, manipulating, and then training a model with the data. At each stage we will be demonstrating how to perform a given task on the GPU with RAPIDS, before asking you to refactor working CPU-only code to run more performantly on the GPU. As a final exercise, you will be asked to implement additional features and retrain the model in order to make better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this link to [No Show Predictive Model Data Generator](No%20Show%20Predictive%20Model%20Data%20Generator.ipynb). When the notebook opens, use the menu to select **Cell -> Run All**. This will generate the synthetic data set we will be using in this lab.\n",
    "\n",
    "After generating the data for his lab it is stored in 2 csv files:\n",
    "\n",
    "- **patient_data.csv** contains 16 attributes about medical patients. It includes personal data such as their age and sex, data about the time and type of their scheduled appointment, information about the day's weather, and their previous rate of being a no-show.\n",
    "- **zipcode_data.csv** contains 2 attributes: the patient's zipcode, which can be used to join this data with that in *patient_data*, and whether or not they have access to public transportation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab does not intend to teach how to do Data Science and assumes you have professional Data Science experience. This lab also assumes competency with the following programming tools and techniques, which will be used without explanation throughout the lab:\n",
    "\n",
    "- The [Python 3 programming language](https://docs.python.org/)\n",
    "- The [Pandas Data Analysis Library](https://pandas.pydata.org/)\n",
    "- The [NumPy Library for Numerical Programming](http://www.numpy.org/)\n",
    "- [One Hot Encoding](https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f)\n",
    "- Machine learning model training with [XGBoost](https://xgboost.readthedocs.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will learn to perform end to end data science workflows on a GPU accelerator using RAPIDS. By the end of this lab you will be able to:\n",
    "\n",
    "- Read data directly onto the GPU\n",
    "- Manipulate data and extract features on the GPU\n",
    "- Use GPU-enabled XGBoost to train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab is using web sockets to supply a connection from your browser to an interactive iPython Notebook on a cloud service provider VM backed by an NVIDIA GPU Accelerator. Execute the cell immediately below to both confirm that your websocket connection is not being blocked by a VPN, or some other security software on your computer, and, for information about the NVIDIA GPU accelerator you will be using during the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built in Python imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional CPU imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for GPU accelerated data manipulation and model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "from cudf.dataframe import DataFrame\n",
    "\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [magic cell](https://ipython.readthedocs.io/en/stable/interactive/magics.html#magic-matplotlib) to enable inline `matplotlib` interaction in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a LabelEncoder and a train_test_split function\n",
    "This is preview of functionality that's coming in the next version of cuDF and cuML.\n",
    "\n",
    "We'll be using these functions in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import nvcategory\n",
    "\n",
    "from librmm_cffi import librmm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _enforce_str(y: cudf.Series) -> cudf.Series:\n",
    "    if y.dtype != \"object\":\n",
    "        return y.astype(\"str\")\n",
    "    return y\n",
    "\n",
    "\n",
    "class Base(object):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._fitted = False\n",
    "\n",
    "    def check_is_fitted(self):\n",
    "        if not self._fitted:\n",
    "            raise TypeError(\"Model must first be .fit()\")\n",
    "\n",
    "\n",
    "class LabelEncoder(Base):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._cats: nvcategory.nvcategory = None\n",
    "        self._dtype = None\n",
    "\n",
    "    def fit(self, y: cudf.Series) -> \"LabelEncoder\":\n",
    "        self._dtype = y.dtype\n",
    "        y = _enforce_str(y)\n",
    "\n",
    "        self._cats = nvcategory.from_strings(y.data)\n",
    "        self._fitted = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, y: cudf.Series) -> cudf.Series:\n",
    "        self.check_is_fitted()\n",
    "        y = _enforce_str(y)\n",
    "        encoded = cudf.Series(\n",
    "            nvcategory.from_strings(y.data)\n",
    "            .set_keys(self._cats.keys())\n",
    "            .values()\n",
    "        )\n",
    "        if -1 in encoded:\n",
    "            raise KeyError(\"Attempted to encode unseen key\")\n",
    "        return encoded\n",
    "\n",
    "    def fit_transform(self, y: cudf.Series) -> cudf.Series:\n",
    "        self._dtype = y.dtype\n",
    "        y = _enforce_str(y)\n",
    "        self._cats = nvcategory.from_strings(y.data)\n",
    "        self._fitted = True\n",
    "        arr: librmm.device_array = librmm.device_array(\n",
    "            y.data.size(), dtype=np.int32\n",
    "        )\n",
    "        self._cats.values(devptr=arr.device_ctypes_pointer.value)\n",
    "        return cudf.Series(arr)\n",
    "\n",
    "    def inverse_transform(self, y: cudf.Series):\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "# Given a cudf string column, returns the unique values\n",
    "def get_unique_strings(ds):\n",
    "    c = nvcategory.from_strings(ds.data)\n",
    "    return c\n",
    "        \n",
    "def cuml_train_test_split(X_gdf, y_gdf, test_size=0.20, random_state=42):\n",
    "    # Identify shape and indices\n",
    "    n_rows, n_columns = X_gdf.shape\n",
    "    train_size = 1- test_size\n",
    "    train_index = int(n_rows * train_size)\n",
    "\n",
    "    # Shuffle data\n",
    "    idx = np.random.randint(0,n_rows-1,n_rows)\n",
    "    X_gdf = X_gdf.set_index(idx)\n",
    "    y_gdf = y_gdf.set_index(idx)\n",
    "    \n",
    "    X_gdf = X_gdf.sort_index()\n",
    "    y_gdf = y_gdf.sort_index()\n",
    "    \n",
    "    # Split into train & test data\n",
    "    X_train, y_train = X_gdf[:train_index], y_gdf[:train_index]\n",
    "    X_test, y_test = X_gdf[train_index:], y_gdf[train_index:]\n",
    "    del X_gdf, y_gdf\n",
    "       \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the following `Timer` for easy perfomance profiling throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from time import time\n",
    "from time import sleep\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "class Timer(object):\n",
    "    def __init__(self):\n",
    "        self._timer = default_timer\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.stop()\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer.\"\"\"\n",
    "        self.start = self._timer()\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer. Calculate the interval in seconds.\"\"\"\n",
    "        self.end = self._timer()\n",
    "        self.interval = self.end - self.start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom timer can conveniently be used in the following ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_num = 100000\n",
    "\n",
    "t = Timer()\n",
    "t.start()\n",
    "\n",
    "for i in range(big_num):\n",
    "    r = 1\n",
    "\n",
    "t.stop()\n",
    "\n",
    "print('Print time using t.start() and t.stop(): \\t{:.6f}'.format(t.interval))\n",
    "\n",
    "with Timer() as t:\n",
    "    for i in range(big_num):\n",
    "        r = 1\n",
    "\n",
    "print('Print time using `with` statment: \\t\\t{:.6f}'.format(t.interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAPIDS enables reading data on disk directly to GPU memory where it can be explored and manipulated on massively parallel NVIDIA GPUs. In this section we will demonstrate common ways to read data directly into GPU memory, noting the speed up over loading data to the CPU, before moving on to exploring and manipulating data on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting Data to the CPU with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we store the paths to the 2 csv files containing our previously generated data into variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data_path = 'patient_data.csv'\n",
    "zipcode_data_path = 'zipcode_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use `Pandas.DataFrame.read_csv` to load the data in the csv files into 2 Pandas DataFrames, `patient_pdf` and `zipcode_pdf`. Take note of the informational printouts, in particular the time it took to load the data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    patient_pdf = pd.read_csv(patient_data_path)\n",
    "\n",
    "pdf_read_time = t.interval\n",
    "print('Time: {:.1f}s'.format(pdf_read_time))\n",
    "print(\"Samples: {:.1f} million\".format(patient_pdf.shape[0]/1E6))\n",
    "print(\"Features:\", patient_pdf.shape[1])\n",
    "print(\"Dataset size: {:.1f} GB\".format(sys.getsizeof(patient_pdf)/1E9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    zipcode_pdf = pd.read_csv(zipcode_data_path)\n",
    "\n",
    "zipcode_pdf_read_time = t.interval\n",
    "print('Time: {:.1f}s'.format(zipcode_pdf_read_time))\n",
    "print(\"Samples: {:.1f} million\".format(zipcode_pdf.shape[0]/1E6))\n",
    "print(\"Features:\", zipcode_pdf.shape[1])\n",
    "print(\"Dataset size: {:.1f} GB\".format(sys.getsizeof(zipcode_pdf)/1E9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting Data to the GPU with cuDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAPIDS provides a GPU accelerated DataFrame library, with a very similar API to Pandas, in [cuDF](https://github.com/rapidsai/cudf). cuDF (*cu* as in [CUDA](https://developer.nvidia.com/about-cuda), the platform enabling general purpose programming on NVIDIA GPU accelerators) is a DataFrame manipulation library which uses the columnar memory format standard of [Apache Arrow](https://arrow.apache.org/).\n",
    "\n",
    "With cuDF we can load data directly to GPU memory just as we would to CPU memory with Pandas. The following uses `cudf.read_csv` to read data in a csv file to GPU memory returning a **GPU** DataFrame, commonly refered to as a **`gdf`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    patient_gdf = cudf.read_csv(patient_data_path)\n",
    "\n",
    "gdf_read_time = t.interval\n",
    "print('Time: {:.1f}s'.format(gdf_read_time))\n",
    "print(\"Samples: {:.1f} million\".format(patient_gdf.shape[0]/1E6))\n",
    "print(\"Features:\", patient_gdf.shape[1])\n",
    "print(\"Dataset size: {:.1f} GB\".format(sys.getsizeof(patient_gdf)/1E9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read DataFrame from csv speedup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Read time on GPU was {:.2f}x faster than on CPU.\".format(pdf_read_time / gdf_read_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can configure how much data to show in the summary view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cudf.settings import set_options\n",
    "\n",
    "format_options =  {\n",
    "    'nrows': 50,\n",
    "    'ncols': 12\n",
    "}\n",
    "\n",
    "with set_options(formatting=format_options):\n",
    "        print(patient_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Load Zipcode Data to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the zipcode data into GPU memory, creating a GPU DataFrame called `zipcode_gdf`.\n",
    "\n",
    "- Recall that the path to the csv file containing the data is currently stored in the `zipcode_data_path` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_gdf = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zipcode_gdf) # Use this cell after you complete the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Manipulation with cuDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have used cuDF to create two GPU DataFrames, `patient_gdf` and `zipcode_gdf`, we can begin to explore and manipulate the data much as we would using a Pandas DataFrame. Much of the `cuDF.DataFrame` API is identical to that of `pandas.DataFrame`, requiring no modification. When and if modifications are needed, please refer to the [cuDF API Reference](https://rapidsai.github.io/projects/cudf/en/latest/api.html), and/or the [RAPIDS Cheat Sheet](https://rapids.ai/assets/files/cheatsheet.pdf).\n",
    "\n",
    "cuDF, along with the entire RAPIDS software suite, is open source, and undergoing very active development. For feature requests, bug reports, or to make contributions, please consider visiting the cuDF repo at [github.com/rapidsai/cudf](https://github.com/rapidsai/cudf).\n",
    "\n",
    "Let's proceed to some basic data exploration and manipulation with cuDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a single column with cuDF is just like with Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_gdf['AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integer slicing for row selection is also identical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_gdf[2:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is selecting by rows and labels using `loc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_gdf.loc[0:5, ['AGE']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean indexing is quite similar to  Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = ['AGE', 'GENDER', 'INSURANCE']\n",
    "ages_greater_than_ninety = patient_gdf[select_columns][patient_gdf.AGE > 90]\n",
    "print(ages_greater_than_ninety)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Create a GPU DataFrame with a Subset of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a GPU DataFrame `ages_of_no_shows_gdf` which contains `AGE` and `NO_SHOW_RATE` columns and is a subselection of the `patient_gdf` DataFrame (our already existing patient data) of patients who have a `NO_SHOW_RATE` greater than `0.7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_of_no_shows_gdf = [] # TODO: populate this as a GPU DataFrame as described above.\n",
    "print(age_of_no_shows_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Unique Values in a Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.unique()` for numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_gdf['DEPT_ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For string columns, use the `get_unique_strings` functions we defined at the top the notebook.\n",
    "This is a temporary approach till we'll `.unique()` supports strings columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_unique_strings(patient_gdf['INSURANCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that there are some empty `None` values in this column. \n",
    "So let's replace it with the value of `OTHER` and look at the unique values again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_gdf['INSURANCE'] = patient_gdf['INSURANCE'].fillna('OTHER')\n",
    "print(get_unique_strings(patient_gdf['INSURANCE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting between GPU DataFrame and Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each GPU DataFrame can invoke the method `to_pandas` to return a Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(patient_gdf.to_pandas()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may wish to convert data to Pandas so that you can visualize it using tools like Matplotlib. As an example, we'll group the patient data by insurance, and plot it as a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First group the data by INSURANCE\n",
    "insurance_count_gdf = patient_gdf[['INSURANCE', 'LABEL']].groupby('INSURANCE').count()\n",
    "print(insurance_count_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index, so that we can have Insurance back as a column.\n",
    "insurance_count_gdf = insurance_count_gdf.reset_index()\n",
    "\n",
    "# Rename the LABEL column as COUNT for clarity, since it now stores counts by Insurance\n",
    "insurance_count_gdf = insurance_count_gdf.rename({'LABEL': 'COUNT'})\n",
    "\n",
    "print(insurance_count_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, sort this grouped data by Insurance, just for convenience\n",
    "insurance_count_gdf = insurance_count_gdf.sort_values(by='INSURANCE')\n",
    "print(insurance_count_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas and visualize as a bar graph\n",
    "insurance_count_gdf.to_pandas().plot.bar(x='INSURANCE', y='COUNT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU DataFrames also have a `sort_values` method that works just like the Pandas equivalent, only much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns = ['AGE', 'GENDER', 'DISTANCE_FROM_CLINIC', 'LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    gpu_sorted_ages = patient_gdf[select_columns].sort_values(by='AGE')\n",
    "\n",
    "gdf_sort_time = t.interval\n",
    "print('Time: {:.5f}s'.format(gdf_sort_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gpu_sorted_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    pdf_sorted_ages = patient_pdf[select_columns].sort_values(by='AGE')\n",
    "\n",
    "pdf_sort_time = t.interval\n",
    "print('Time: {:.5}s'.format(pdf_sort_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sort on GPU was {:.2f}x faster than on CPU.\".format(pdf_sort_time / gdf_sort_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Write the 1000 Oldest Patients to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a csv file called `oldest_patient_summary.csv` with the `AGE`, `GENDER`, `ZIPCODE` and `NO_SHOW_RATE` of the 1000 oldest patients currently in `patient_gdf`, sorted in ascending order by their `NO_SHOW_RATE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_patients_details_path = 'oldest_patients_details.csv'\n",
    "\n",
    "# TODO: Follow the instructions above to write the specified data to oldest_patients_details.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying User Defined Functions to Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like with Pandas, you can perform operations on every value in a column like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_gdf['AGE_NEXT_YEAR'] = patient_gdf['AGE'] + 1\n",
    "print(patient_gdf[['AGE', 'AGE_NEXT_YEAR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply functions to columns of data using `cudf.Series.applymap` which is analogous to `pandas.Series.apply`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double = lambda x : x * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    patient_gdf['DOUBLED_AGE'] = patient_gdf['AGE'].applymap(double)\n",
    "\n",
    "gdf_apply_time = t.interval\n",
    "print('Time: {:.5f}s'.format(gdf_apply_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(patient_gdf[['AGE', 'DOUBLED_AGE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    patient_pdf['DOUBLED_AGE'] = patient_pdf['AGE'].apply(double)\n",
    "\n",
    "pdf_apply_time = t.interval\n",
    "print('Time: {:.5f}s'.format(pdf_apply_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Apply function on GPU was {:.2f}x faster than on CPU.\".format(pdf_apply_time / gdf_apply_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to keep those new columns around, so let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_pdf.drop(['DOUBLED_AGE'], axis=1)\n",
    "\n",
    "patient_gdf.drop('DOUBLED_AGE')\n",
    "patient_gdf.drop('AGE_NEXT_YEAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying User Defined Functions to Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply user defined functions to rows using `cudf.DataFrame.apply_rows` which is similar to `pandas.DataFrame.apply(index=1)`. When using `apply_rows` we:\n",
    "\n",
    "1. Define a function with function parameters for a given row's input columns and output columns, as well as any keyword arguments we might wish to pass in\n",
    "2. Utilize input column arguments in modifying or creating output column arguments\n",
    "3. Invoke `apply_rows` by providing the user-defined function, a list of input columns, a dict of output columns with their types, and a dict of keyword arguments with their arguments.\n",
    "\n",
    "The following example creates a new `IS_SENIOR` column for each row in `patient_gdf`, using existing date from the `AGE` and `INSURANCE` columns.\n",
    "\n",
    "Since these lambda functions don't yet support strings, we'll have to convert the `INSURANCE` column from strings to numeric IDs. This is called label encoding and we'll look into this in more detail a little later. For now, you just need to know that label encoding converts the insurance strings to some mapped integers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_gdf['INSURANCE'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "patient_gdf['INSURANCE'] = le.fit_transform(patient_gdf['INSURANCE'])\n",
    "print(patient_gdf['INSURANCE'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_is_senior(AGE, INSURANCE, IS_SENIOR, kwarg1):\n",
    "    for i, (age, insurance) in enumerate(zip(AGE, INSURANCE)):\n",
    "        if (age >= 65) or (insurance == 1): # Insurance 1 == MEDICARE\n",
    "            IS_SENIOR[i] = 1\n",
    "        else:\n",
    "            IS_SENIOR[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_is_senior_gdf = patient_gdf.apply_rows(add_is_senior, \n",
    "                                           incols=['AGE', 'INSURANCE'], \n",
    "                                           outcols=dict(IS_SENIOR=np.int64), \n",
    "                                           kwargs=dict(kwarg1=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(add_is_senior_gdf[['AGE', 'INSURANCE', 'IS_SENIOR']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Implement an AGE_BUCKET Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we know, based on our subject matter expertise, that there are certain natural age clusters and that we would like to use that knowledge by categorizing our patients into one of 6 age buckets, and create a new column, `AGE_BUCKET` to store which of the 6 buckets they are in. In order to do this we will apply the `age_bucket_gpu` function, provided below, to each row in `patient_gdf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_bucket_gpu(AGE, AGE_BUCKET, kwarg1):\n",
    "    for i, age in enumerate(AGE):\n",
    "        age_bucket = 0\n",
    "        if (age<18):\n",
    "            age_bucket = 0\n",
    "        elif (age<30):\n",
    "            age_bucket = 1\n",
    "        elif (age<40):\n",
    "            age_bucket = 2\n",
    "        elif (age<50):\n",
    "            age_bucket = 3\n",
    "        elif (age<60):\n",
    "            age_bucket = 4\n",
    "        elif (age>60):\n",
    "            age_bucket = 5\n",
    "\n",
    "        AGE_BUCKET[i] = age_bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `apply_rows` below along with `age_bucket_gpu` to create this new column. The new column `AGE_BUCKET` should have the dtype `np.int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert age into buckets\n",
    "with Timer() as t:\n",
    "    patient_gdf = patient_gdf.apply_rows() # TODO: Pass the correct arguments into `apply_rows`\n",
    "\n",
    "# We won't be performing this operation on `patient_pdf` until further into the notebook,\n",
    "# but we will store the GPU time here to use for comparison later.\n",
    "gdf_bucket_time = t.interval\n",
    "print('Time: {:.5f}s'.format(gdf_bucket_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to CPU Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've successfully completed the exercise run the following cells to execute the same operations on the CPU so that we can compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_bucket_cpu(row):\n",
    "    age = row.AGE\n",
    "    age_bucket = 0\n",
    "    if (age<18):\n",
    "        age_bucket = 0\n",
    "    elif (age<30):\n",
    "        age_bucket = 1\n",
    "    elif (age<40):\n",
    "        age_bucket = 2\n",
    "    elif (age<50):\n",
    "        age_bucket = 3\n",
    "    elif (age<60):\n",
    "        age_bucket = 4\n",
    "    elif (age>60):\n",
    "        age_bucket = 5\n",
    "\n",
    "    return age_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    patient_pdf['AGE_BUCKET'] = patient_pdf.apply(age_bucket_cpu, axis=1)\n",
    "\n",
    "pdf_bucket_time = t.interval\n",
    "print('Time: {:.1f}s'.format(pdf_bucket_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bucketing on GPU was {:.2f}x faster than on CPU.\".format(pdf_bucket_time / gdf_bucket_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop AGE Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully created the `AGE_BUCKET` column for each row in `patient_gdf`, execute the cell below to drop the `AGE` column which is no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_gdf.drop('AGE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label and One Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now get deeper into Label Encodign and One Hot Encoding. \n",
    "\n",
    "We'll use the LabelEncoder we defined at the very beginning, to encode string columns to integers. \n",
    "\n",
    "We'll then one hot encode this column using the `cudf.DataFrame.one_hot_encoding` api, which expects the following arguments:\n",
    "\n",
    "- A source column\n",
    "- A prefix for dummy column names\n",
    "- A sequence of integer encoded category values\n",
    "- The dtype for value outputs, which defaults to float64\n",
    "\n",
    "Here we use `cudf.DataFrame.one_hot_encode` to one hot encode a DataFrame containing values for scientists with 6 different names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple dataframe\n",
    "scientists_dict = {\n",
    "    1: 'Kepler',\n",
    "    2: 'Maxwell',\n",
    "    3: 'Pascal',\n",
    "    4: 'Volta',\n",
    "    5: 'Turing',\n",
    "    6: 'Curie'\n",
    "}\n",
    "\n",
    "scientists_gdf = cudf.DataFrame({\n",
    "    'NAMES': scientists_dict.values()\n",
    "})\n",
    "print(scientists_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encode the NAMES column \n",
    "le = LabelEncoder()\n",
    "scientists_gdf['NAMES'] = le.fit_transform(scientists_gdf['NAMES'])\n",
    "print(scientists_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the unique encoded values \n",
    "scientists =scientists_gdf.NAMES.unique()\n",
    "print(scientists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, one hot enocde this numeric column\n",
    "scientists_gdf = scientists_gdf.one_hot_encoding('NAMES', 'NAMES', scientists, dtype='int32')\n",
    "print(scientists_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Complete One Hot Encoding Function\n",
    "\n",
    "The following function, `one_hot_encode_and_drop` will be used extensively below to one hot encode our categorical data columns and then drop the unencoded columns. Complete the call to `patient_gdf.one_hot_encoding` so that it works as expected. Look at how `one_hot_encode_and_drop` is used in `one_hot_encode_cat_columns` below to support your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_and_drop(gdf, column_name, label_encode=False):   \n",
    "    if label_encode is True:\n",
    "        le = LabelEncoder()\n",
    "        gdf[column_name] = le.fit_transform(gdf[column_name])\n",
    "\n",
    "    cats = gdf[column_name].unique()\n",
    "    \n",
    "    gdf = gdf.one_hot_encoding() # TODO: Pass the correct arguments into `gdf.one_hot_encoding`    \n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encode Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we define `one_hot_encode_cat_columns` which utilizes both the `LabelEncoder` the `one_hot_encode_and_drop` function you just completed, to one hot encode all the categorical columns in `patient_gdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You do not need to modify this function. However, you need to complete the definition for\n",
    "# `one_hot_encode_and_drop` above before it will work properly.\n",
    "\n",
    "def one_hot_encode_cat_columns(gdf):\n",
    "        for col in ['GENDER', 'VISIT_TYPE', 'DEPT_SPECIALTY', 'APPT_WEEKDAY']:\n",
    "             gdf = one_hot_encode_and_drop(gdf, col, label_encode=True)\n",
    "    \n",
    "        # The following columns are already encoded as integers and don't need to be label encoded\n",
    "        for col in ['AGE_BUCKET', 'INSURANCE', 'DEPT_ID' ]:\n",
    "            gdf = one_hot_encode_and_drop(gdf, col, label_encode=False)\n",
    "    \n",
    "        return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally before training we will use `prep_for_training` to do some final cleanup, as well as to split the data into test and training sets. \n",
    "\n",
    "We'll use the cuml_train_test_split function that we defined at the very beginning. Note that we need to convert the `cudf` object to `DMatrix` before we pass it to `XGBoost` for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_training(patient_gdf):\n",
    "    \n",
    "    final_features = patient_gdf.columns.tolist()\n",
    "    if 'LABEL' in final_features:\n",
    "        final_features.remove('LABEL')\n",
    "    if 'DAY' in final_features:\n",
    "        final_features.remove('DAY')\n",
    "    if 'MONTH' in final_features:\n",
    "        final_features.remove('MONTH')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = cuml_train_test_split(patient_gdf[final_features], patient_gdf[['LABEL']])\n",
    "    \n",
    "    # Convert to DMatrices\n",
    "    dtrain = xgboost.DMatrix(X_train, y_train)\n",
    "    dtest = xgboost.DMatrix(X_test, y_test)\n",
    "    del X_train, X_test, y_train\n",
    "\n",
    "    return  dtrain, dtest, y_test.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back On the CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on to train our model, we provide here a couple of cells which will carry out, on the CPU, the operations just completed on the GPU so that we can compare performance below. For convenience, we have combined the one hot encoding and test/train splitting into one function for the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_cat_columns_cpu(pdf):\n",
    "    # One Hot Encode categorical values\n",
    "    pdf = pd.concat([pdf, pd.get_dummies(pdf.AGE_BUCKET, prefix=\"AGE_BUCKET\")], axis=1)\n",
    "    pdf = pd.concat([pdf, pd.get_dummies(pdf.GENDER, prefix=\"GENDER\")], axis=1)\n",
    "    pdf = pd.concat([pdf, pd.get_dummies(pdf.INSURANCE, prefix=\"INSURANCE\")], axis=1)\n",
    "    pdf = pd.concat([pdf, pd.get_dummies(pdf.VISIT_TYPE, prefix=\"VISIT_TYPE\")], axis=1)\n",
    "    pdf = pd.concat([pdf, pd.get_dummies(pdf.DEPT_SPECIALTY, prefix=\"DEPT_SPECIALTY\")], axis=1)\n",
    "    pdf = pd.concat([pdf, pd.get_dummies(pdf.DEPT_ID, prefix=\"DEPT\")], axis=1)\n",
    "    pdf = pd.concat([pdf, pd.get_dummies(pdf.APPT_WEEKDAY, prefix=\"APPT_WEEKDAY\")], axis=1)\n",
    "\n",
    "    # Drop labels after One Hot Encoding\n",
    "    pdf = pdf.drop(['AGE', 'GENDER', 'INSURANCE', 'VISIT_TYPE', 'DEPT_SPECIALTY', 'DEPT_ID', 'APPT_WEEKDAY'], axis=1)\n",
    "    \n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_training_cpu(pdf):\n",
    "    # Create final features\n",
    "    final_features = pdf.columns.tolist()\n",
    "    if 'LABEL' in final_features:\n",
    "        final_features.remove('LABEL')\n",
    "    if 'DAY' in final_features:\n",
    "        final_features.remove('DAY')\n",
    "    if 'MONTH' in final_features:\n",
    "        final_features.remove('MONTH')\n",
    "\n",
    "    # Separate features and labels\n",
    "    x_df = pdf[final_features]\n",
    "    y_df = pdf['LABEL']\n",
    "\n",
    "    # Split train and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.20, random_state=42)\n",
    "\n",
    "    # Convert train and test into xgboost format (DMatrix)\n",
    "    dtrain = xgboost.DMatrix(data=X_train, label=y_train)\n",
    "    dtest = xgboost.DMatrix(data=X_test, label=y_test)\n",
    "\n",
    "    del pdf, x_df, y_df\n",
    "    del X_train, X_test, y_train\n",
    "\n",
    "    return dtrain, dtest, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Data Prep Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will perform our data prep steps on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    merged_gdf = patient_gdf.merge(zipcode_gdf, how=\"left\", on='ZIPCODE')\n",
    "gdf_merge_time = t.interval\n",
    "print('Merge Time: {:.1f}s'.format(gdf_merge_time))\n",
    "\n",
    "with Timer() as t:\n",
    "    encoded_gdf = one_hot_encode_cat_columns(merged_gdf)\n",
    "gdf_one_hot_encode_time = t.interval\n",
    "print('One Hot Encode Time: {:.1f}s'.format(gdf_one_hot_encode_time))\n",
    "\n",
    "with Timer() as t:\n",
    "    dtrain_gpu, dtest_gpu, y_test_gpu = prep_for_training(encoded_gdf)\n",
    "gdf_dmatrix_time = t.interval\n",
    "print('DMatrix Generation Time: {:.1f}s'.format(gdf_dmatrix_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now on the CPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    merged_pdf = pd.merge(patient_pdf, zipcode_pdf, on='ZIPCODE')\n",
    "pdf_merge_time = t.interval\n",
    "print('Merge Time: {:.1f}s'.format(pdf_merge_time))\n",
    "\n",
    "with Timer() as t:\n",
    "    encoded_pdf = one_hot_encode_cat_columns_cpu(merged_pdf)\n",
    "pdf_one_hot_encode_time = t.interval\n",
    "print('One Hot Encode Time: {:.1f}s'.format(pdf_one_hot_encode_time))\n",
    "\n",
    "with Timer() as t:    \n",
    "    dtrain_cpu, dtest_cpu, y_test_cpu = prep_for_training_cpu(encoded_pdf)\n",
    "pdf_dmatrix_time = t.interval\n",
    "print('DMatrix Generation Time: {:.1f}s'.format(pdf_dmatrix_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merge time on GPU was {:.2f}x faster than on CPU.\".format(pdf_merge_time / gdf_merge_time))\n",
    "print(\"One Hot Encode time on GPU was {:.2f}x faster than on CPU.\".format(pdf_one_hot_encode_time / gdf_one_hot_encode_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [XGBoost](https://xgboost.readthedocs.io/) to train models on the GPU is very easy and very similar to how you would use it on a CPU. \n",
    "\n",
    "The only difference we need to make to train with XGBoost on the GPU is to provide the `n_gpus` parameter, which indicates how many GPUs we would like to utilize in training. When set to `-1` as we are doing below, we indicate that we wish to use all available GPUs. Additionally we must specify the `tree_method` to be `gpu_hist`. Note the near identical precision with a roughly 10x speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpu(dtrain):\n",
    "    gpu_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'n_gpus': 1,\n",
    "        'booster':'gbtree',\n",
    "        'nround': 15,\n",
    "        'max_depth': 3,\n",
    "        'alpha': 0.9,\n",
    "        'eta': 0.1,\n",
    "        'gamma': 0.1,\n",
    "        'learning_rate': 0.5,\n",
    "        'subsample': 1,\n",
    "        'reg_lambda': 1,\n",
    "        'scale_pos_weight': 2,\n",
    "        'min_child_weight': 30,\n",
    "        'tree_method': 'gpu_hist',\n",
    "        'loss': 'ls',\n",
    "        'max_features': 'auto',\n",
    "        'criterion': 'friedman_mse',\n",
    "        'grow_policy': 'lossguide',\n",
    "    }\n",
    "    \n",
    "    return xgboost.train(gpu_params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    clf_gpu = train_gpu(dtrain_gpu)\n",
    "\n",
    "gdf_train_time = t.interval\n",
    "print('Time: {:.1f}s'.format(gdf_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gpu = clf_gpu.predict(dtest_gpu)\n",
    "auc_gpu = roc_auc_score(y_test_gpu, y_pred_gpu)\n",
    "print(\"AUC: {:.3f}\".format(auc_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the CPU for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cpu(dtrain):\n",
    "    cpu_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'booster':'gbtree',\n",
    "        'nround': 10,\n",
    "        'max_depth': 3,\n",
    "        'alpha': 0.9,\n",
    "        'eta': 0.1,\n",
    "        'gamma': 0.1,\n",
    "        'learning_rate': 0.5,\n",
    "        'subsample': 1,\n",
    "        'reg_lambda': 1,\n",
    "        'scale_pos_weight': 2,\n",
    "        'min_child_weight': 30,\n",
    "        'tree_method': 'hist',\n",
    "        'loss': 'ls',\n",
    "        'max_features': 'auto',\n",
    "        'criterion': 'friedman_mse',\n",
    "        'grow_policy': 'lossguide',\n",
    "    }\n",
    "    \n",
    "    return xgboost.train(cpu_params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer() as t:\n",
    "    clf_cpu = train_cpu(dtrain_cpu)\n",
    "\n",
    "pdf_train_time = t.interval\n",
    "print('Time: {:.1f}s'.format(pdf_train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cpu = clf_cpu.predict(dtest_cpu)\n",
    "auc_cpu = roc_auc_score(y_test_cpu, y_pred_cpu)\n",
    "print(\"AUC: {:.3f}\".format(auc_cpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train on GPU was {:.2f}x faster than on CPU.\".format(pdf_train_time / gdf_train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Before beginning the final exercise, which will require you to make changes throughout the notebook, you may wish to download this notebook by choosing **File -> Download as -> Notebook** in the menu above._\n",
    "\n",
    "As a final exercise you will implement a new feature in the hopes of improving the accuracy of your predictions. Use the `holiday_week_gpu` function defined below, and make any other changes in the notebook that are necessary, to create and populate a `HOLIDAY_WEEK` column which will indicate whether or not a given appointment falls on a week containing a holiday.\n",
    "\n",
    "After you have implemented the feature, rerun `train_and_evaluate_gpu` to see if you've made any improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holiday_week_gpu(DAY, MONTH, HOLIDAY_WEEK, kwarg1):\n",
    "    for i, (day, month) in enumerate(zip(DAY, MONTH)):\n",
    "        holiday_week = 0\n",
    "        if (month==5 and day>24) \\\n",
    "            or (month==7 and day<8) \\\n",
    "            or (month==9 and day<8) \\\n",
    "            or (month==12 and day>21) \\\n",
    "            or (month==1 and day<3):  \\\n",
    "            holiday_week = 1\n",
    "        HOLIDAY_WEEK[i] = holiday_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your work here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have completed this, lab you should be able to:\n",
    "\n",
    "- Read data directly onto the GPU\n",
    "- Manipulate data and extract features on the GPU\n",
    "- Use GPU-enabled XGBoost to train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following list of additional resources to get, learn more about, and practice with RAPIDS:\n",
    "\n",
    "- [RAPIDS Home Page](https://rapids.ai/)\n",
    "- [Get RAPIDS](https://rapids.ai/start.html) (see \"Get RAPIDS\" section)\n",
    "- [RAPIDS Cheat Sheet](https://rapids.ai/assets/files/cheatsheet.pdf)\n",
    "- [RAPIDS on GitHub](https://github.com/RAPIDSai)\n",
    "- [Collection of RAPIDS Blog Posts](https://medium.com/rapids-ai)\n",
    "- [cuDF API Reference](https://rapidsai.github.io/projects/cudf/en/latest/api.html)\n",
    "- [10 Minutes to cuDF](https://rapidsai.github.io/projects/cudf/en/latest/10min.html)\n",
    "- [Notebooks repo](https://github.com/rapidsai/notebooks)\n",
    "- [Notebooks-Extended repo](https://github.com/rapidsai/notebooks-extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
